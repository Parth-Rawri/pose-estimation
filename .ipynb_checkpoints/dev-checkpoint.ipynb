{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44d5df24-db32-43ce-8f6c-f80610e98033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py\n",
    "\n",
    "def transform_is_valid(transform, tolerance=1e-3):\n",
    "    \"\"\"\n",
    "    checks if transformation is a valid SE(3)\n",
    "    args:\n",
    "        transform (numpy.array [4,4])\n",
    "        tolerance (float, optional) \n",
    "    returns: \n",
    "        bool: True is `transform` is valid else False\n",
    "    \"\"\"\n",
    "    shape = transform.shape == (4,4)\n",
    "    isreal = np.all(np.isreal(transform))\n",
    "    last_row = np.allclose(transform[3, :], [0, 0, 0, 1], atol=tolerance)\n",
    "    R, T = transform[:3, :3], transform[:3, -1]\n",
    "    RtR = R.transpose() @ R\n",
    "    RRt = R @ R.transpose()\n",
    "    det = np.linalg.det(R)\n",
    "    valid = isreal and shape and np.allclose(RtR, np.eye(3), atol=tolerance) and np.allclose(RRt, np.eye(3), atol=tolerance) and np.isclose(det, 1, atol=tolerance)\n",
    "    return valid\n",
    "\n",
    "\n",
    "def camera_to_image(K, points):\n",
    "    \"\"\"\n",
    "    project points from camera coordinate system to digital image plane\n",
    "    args:\n",
    "        K (numpy.array [3, 3])\n",
    "        points [n, 3]\n",
    "    returns:\n",
    "        numpy.array [n, 2]: n 2D projections of the input points on the image plane\n",
    "    \"\"\"\n",
    "    fx, fy = K[0,0], K[1,1] \n",
    "    cx, cy = K[0,2], K[1,2]\n",
    "    x, y, z = points[:,0], points[:,1], points[:,2]\n",
    "    u, v = (np.round((fx * (x/z) + cx))).astype(int), (np.round((fy * (y/z) + cy))).astype(int)\n",
    "    points = np.vstack((u, v)).T\n",
    "    return points\n",
    "\n",
    "\n",
    "def world_to_camera(camera_pose, world_points):\n",
    "    \"\"\"\n",
    "    Transform the points in the world frame to the camera frame, using camera pose.\n",
    "    args:\n",
    "        camera_pose (numpy.array [4, 4])\n",
    "        points [n, 3]\n",
    "    returns:\n",
    "        numpy.array [n, 3]\n",
    "    \"\"\"\n",
    "    world_coords_h = np.hstack((world_points, np.ones((world_points.shape[0], 1), dtype=np.float32)))\n",
    "    camera_pose = np.linalg.inv(camera_pose)\n",
    "    camera_coords_h = (camera_pose @ world_coords_h.T).T\n",
    "    camera_coords_c = camera_coords_h[:, :3]\n",
    "    return camera_coords_c\n",
    "\n",
    "\n",
    "def depth_to_point_cloud(K, depth_image):\n",
    "    \"\"\"\n",
    "    back project a depth image to a point cloud\n",
    "    args:\n",
    "        K (numpy.array [3, 3])\n",
    "        depth_image (numpy.array [h, w]): each entry is a z depth value\n",
    "    Returns:\n",
    "        numpy.array [n, 3]: each row represents a different valid 3D point\n",
    "    \"\"\"\n",
    "    fx, fy = K[0,0], K[1,1] \n",
    "    cx, cy = K[0,2], K[1,2]\n",
    "    h, w = depth_image.shape\n",
    "    u, v = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    u, v = u.flatten(u), u.flatten(v)\n",
    "    Z = depth_image.flatten()\n",
    "    valid = Z > 0\n",
    "    u, v, Z = u[valid], v[valid], Z[valid]\n",
    "    X, Y = (u - cx) * Z/fx, (v - cy) * Z/fy\n",
    "    points = np.vstack((X, Y, Z)).T\n",
    "    return points    \n",
    "\n",
    "\n",
    "# test_rgbd_image_to_points(...) that will read an RGB-D image and convert it into point cloud and save it as test.ply.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b723deaa-f905-4c08-820f-1da8de27d275",
   "metadata": {},
   "source": [
    ".copy(order='C'): Ensures the array is stored in C-contiguous order, which is important for performance in certain NumPy operations.\n",
    "astype(int): Converts the voxel bounds into integer values because the number of voxels must be a whole number.\n",
    "\n",
    "Use **stack** when you want to add a new dimension.\n",
    "Use **concatenate** when you want to merge along an existing dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "daace64a-4a0a-4e41-a1a5-5ab00cd3e300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel volume size: 150 x 150 x 80 - # voxels: 1800000\n",
      "Fusing frame 1/5\n",
      "Fusing frame 2/5\n",
      "Fusing frame 3/5\n",
      "Fusing frame 4/5\n",
      "Fusing frame 5/5\n",
      "Average FPS: 0.50\n",
      "Saving mesh to mesh.ply...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# tsdf.py\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "\n",
    "class TSDFVolume:\n",
    "    def __init__(self, volume_bounds, voxel_size):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            volume_bounds (numpy.array [3, 2]): rows index [x, y, z] and cols index [min_bound, max_bound]. Units are in meters.\n",
    "            voxel_size (float): The side length of each voxel in meters.\n",
    "        \"\"\"\n",
    "        # raise value error if not conformant\n",
    "        if volume_bounds.shape != (3,2):\n",
    "            raise ValueError(\"Incorrect Shape\")\n",
    "        if voxel_size <= 0.0:\n",
    "            raise ValueError(\"Invalid Size\")\n",
    "            \n",
    "        \"\"\"Numpy array [3, 2] of float32s, where rows index [x, y, z] and cols index [min_bound, max_bound]. Units are in meters.\"\"\"\n",
    "        self._volume_bounds = volume_bounds\n",
    "        \n",
    "        \"\"\"float side length in meters of each 3D voxel cube.\"\"\"\n",
    "        self._voxel_size = float(voxel_size)\n",
    "        \n",
    "        \"\"\"float tsdf truncation margin, the max allowable distance away from a surface in meters.\"\"\"\n",
    "        self._truncation_margin = 2 * self._voxel_size\n",
    "        # adjust volume bounds\n",
    "        self.voxel_bounds = np.ceil((self._volume_bounds[:,1]-self._volume_bounds[:,0])/self._voxel_size).copy(order='C').astype(int) \n",
    "        self._volume_bounds[:, 1] = self._volume_bounds[:, 0] + (self.voxel_bounds * self._voxel_size)\n",
    "        \n",
    "        \"\"\"Origin of the voxel grid in world coordinate. Units are in meters.\"\"\"\n",
    "        self._volume_origin = self._volume_bounds[:,0].copy(order='C').astype(np.float32)\n",
    "        print(f'Voxel volume size: {self.voxel_bounds[0]} x {self.voxel_bounds[1]} x {self.voxel_bounds[2]} - # voxels: {self.voxel_bounds[0] * self.voxel_bounds[1] * self.voxel_bounds[2]}')\n",
    "        \n",
    "        \"\"\"Numpy array of float32s representing tsdf volume where each voxel represents a volume self._voxel_size^3. Shape of this volume is determined by (max_bound - min_bound)/ self._voxel_size. Each entry contains the distance to the nearest surface in meters, truncated by self._truncation_margin.\"\"\"\n",
    "        self._tsdf_volume = np.ones(self.voxel_bounds).astype(np.float32)\n",
    "        \n",
    "        \"\"\"Numpy array of float32s with shape [self._tsdf_volume.shape, 3] in range [0.0, 255.0]. So each entry in the volume contains the average r, g, b color.\"\"\"\n",
    "        self._color_volume = np.zeros(np.append(self.voxel_bounds, 3)).astype(np.float32)\n",
    "        \n",
    "        \"\"\"Numpy array [number of voxels, 3] of uint8s. [[0, 0, 0], [0, 0, 1], ...,]. When a new observation is made, we need to determine which of these voxel coordinates is \"valid\" so we can decide what voxels to update.\"\"\"\n",
    "        xv, yv, zv = np.meshgrid(\n",
    "            range(self.voxel_bounds[0]),\n",
    "            range(self.voxel_bounds[1]),\n",
    "            range(self.voxel_bounds[2]),\n",
    "        )\n",
    "        self._voxel_coords = np.vstack((xv.flatten(), yv.flatten(), zv.flatten())).astype(int).T\n",
    "\n",
    "    def get_mesh(self):\n",
    "        \"\"\"\n",
    "        Reconstructs a 3D mesh from a tsdf volume using the marching cubes algorithm\n",
    "        Returns:\n",
    "            numpy.array [n, 3]: each row represents a 3D point.\n",
    "            numpy.array [k, 3]: each row is a list of point indices used to render triangles.\n",
    "            numpy.array [n, 3]: each row represents the normal vector for the corresponding 3D point.\n",
    "            numpy.array [n, 3]: each row represents the color of the corresponding 3D point.\n",
    "        \"\"\"\n",
    "        # Marching cubes\n",
    "        voxel_points, triangles, normals, _ = measure.marching_cubes(self._tsdf_volume, level=0, method='lewiner')\n",
    "        points_ind = np.round(voxel_points).astype(int)\n",
    "        points = self.voxel_to_world(self._volume_origin, voxel_points, self._voxel_size)\n",
    "        \n",
    "        # Get vertex colors\n",
    "        rgb_vals = self._color_volume[points_ind[:, 0], points_ind[:, 1], points_ind[:, 2]]\n",
    "        colors_r, colors_g, colors_b = rgb_vals[:, 0], rgb_vals[:, 1], rgb_vals[:, 2]\n",
    "        colors = np.floor(np.asarray([colors_r, colors_g, colors_b])).T\n",
    "        colors = colors.astype(np.uint8)\n",
    "        return points, triangles, normals, colors\n",
    "\n",
    "    def get_valid_points(self, depth_image, voxel_u, voxel_v, voxel_z):\n",
    "        \"\"\"Compute a boolean array for indexing the voxel volume. Note that every time the method integrate(...) is called, not every voxel in the volume will be updated. This method returns a boolean matrix called valid_points with dimension (n, ), where n = # of voxels. Index i of valid_points will be true if this voxel will be updated, false if the voxel needs not to be updated.\"\"\"\n",
    "        image_height, image_width = depth_image.shape\n",
    "        # Ensure voxel_u and voxel_v are valid integer indices\n",
    "        voxel_u = voxel_u.astype(int)\n",
    "        voxel_v = voxel_v.astype(int)\n",
    "    \n",
    "        # Eliminate pixels not in the image bounds or that are behind the image plane\n",
    "        valid_pixels = np.logical_and(voxel_u >= 0,\n",
    "                                      np.logical_and(voxel_u < image_width,\n",
    "                                      np.logical_and(voxel_v >= 0,\n",
    "                                      np.logical_and(voxel_v < image_height, voxel_z > 0))))\n",
    "    \n",
    "        # Get depths for valid coordinates u, v from the depth image. Zero elsewhere.\n",
    "        depths = np.zeros(voxel_u.shape)\n",
    "        depths[valid_pixels] = depth_image[voxel_v[valid_pixels], voxel_u[valid_pixels]]\n",
    "    \n",
    "        # Filter out zero depth values and depth + truncation margin >= voxel_z\n",
    "        valid_points = np.logical_and(depths > 0, depths+self._truncation_margin >= voxel_z)\n",
    "        return valid_points\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def voxel_to_world(volume_origin, voxel_size, voxel_coords):\n",
    "        \"\"\"Convert from voxel coordinates to world coordinates\"\"\"\n",
    "        return volume_origin + voxel_coords * voxel_size\n",
    "        \n",
    "    @staticmethod\n",
    "    def compute_tsdf(depth_image, voxel_z, truncation_margin, valid_points, valid_pixels):\n",
    "        \"\"\"Compute the new TSDF value for each valid point. We apply truncation and normalization in the end, so that tsdf value is in the range [-1,1].\"\"\"\n",
    "        Z = voxel_z[valid_points]\n",
    "        proj = np.zeros_like(Z)\n",
    "        \n",
    "        for idx, pixel in enumerate(valid_pixels):\n",
    "            u, v = pixel[0], pixel[1]\n",
    "            depth = depth_image[v, u]\n",
    "            proj[idx] = depth - Z[idx]\n",
    "            \n",
    "        for idx, dist in enumerate(proj):\n",
    "            proj[idx] = max(-1, min(1, dist/truncation_margin))\n",
    "\n",
    "        tsdf = proj\n",
    "        return tsdf\n",
    "\n",
    "    @staticmethod\n",
    "    def update_tsdf(tsdf_old, tsdf_new, color_old, color_new):\n",
    "        \"\"\"\n",
    "        Update the TSDF value and color for the voxels that have new observations. \n",
    "        We only update the tsdf and color value when the new absolute value of tsdf_new[i] is smaller than that of tsdf_old[i].\n",
    "        \"\"\"\n",
    "        for idx in range(len(tsdf_new)):\n",
    "            if abs(tsdf_new[idx]) < abs(tsdf_old[idx]):\n",
    "                tsdf_old[idx] = tsdf_new[idx]\n",
    "                color_old[idx, :] = color_new[idx, :]\n",
    "        return tsdf_old, color_old\n",
    "\n",
    "    def integrate(self, color_image, depth_image, camera_intrinsics, camera_pose):\n",
    "        \"\"\"\n",
    "        Integrate an RGB-D observation into the TSDF volume, by updating the tsdf volume, and color volume.\n",
    "        Args:\n",
    "            color_image (numpy.array [h, w, 3]): rgb image.\n",
    "            depth_image (numpy.array [h, w]): 'z' depth image.\n",
    "            camera_intrinsics (numpy.array [3, 3]): given as [[fu, 0, u0], [0, fv, v0], [0, 0, 1]]\n",
    "            camera_pose (numpy.array [4, 4]): SE3 transform representing pose (camera to world)\n",
    "        \"\"\"\n",
    "        color_image = color_image.astype(np.float32)\n",
    "        depth_image = depth_image.astype(np.float32)\n",
    "        voxel_world_coords = self.voxel_to_world(self._volume_origin, self._voxel_size, self._voxel_coords)\n",
    "        voxel_camera_coords = world_to_camera(camera_pose, voxel_world_coords)\n",
    "        voxel_img_coords = camera_to_image(camera_intrinsics, voxel_camera_coords)\n",
    "        voxel_u, voxel_v, voxel_z = voxel_img_coords[:,0], voxel_img_coords[:,1], voxel_camera_coords[:,2]\n",
    "        valid_points = self.get_valid_points(depth_image, voxel_u, voxel_v, voxel_z)\n",
    "        valid_voxels = self._voxel_coords[valid_points]\n",
    "        valid_pixels = voxel_img_coords[valid_points]\n",
    "        tsdf = self.compute_tsdf(depth_image, voxel_z, self._truncation_margin, valid_points, valid_pixels)\n",
    "\n",
    "        tsdf_old  = self._tsdf_volume[valid_voxels[:,0], valid_voxels[:,1], valid_voxels[:,2]]\n",
    "        color_old = self._color_volume[valid_voxels[:,0], valid_voxels[:,1], valid_voxels[:,2]]\n",
    "        color_new = color_image[valid_pixels[:,1].astype(int), valid_pixels[:,0].astype(int)]\n",
    "        \n",
    "        tsdf_updated, color_updated = self.update_tsdf(tsdf_old, tsdf, color_old, color_new)\n",
    "        self._tsdf_volume[valid_voxels[:,0], valid_voxels[:,1], valid_voxels[:,2]] = tsdf_updated\n",
    "        self._color_volume[valid_voxels[:,0], valid_voxels[:,1], valid_voxels[:,2]] = color_updated\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_count = 5\n",
    "    voxel_size = 0.01\n",
    "    volume_bounds = np.array([[-0.75, 0.75], [-0.75,0.75], [0.,0.8]])\n",
    "    camera_intrinsics = np.loadtxt(\"./data/camera-intrinsics.txt\")\n",
    "    tsdf_volume = TSDFVolume(volume_bounds, voxel_size)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    for i in range(image_count):\n",
    "        print(f\"Fusing frame {i+1}/{image_count}\")\n",
    "    \n",
    "        # Load RGB-D image and camera pose\n",
    "        color_image = cv2.imread(f\"./data/frame-{i:06d}.color.png\")\n",
    "        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "        depth_image = cv2.imread(f\"./data/frame-{i:06d}.depth.png\", -1).astype(float) / 1000.0\n",
    "        camera_pose = np.loadtxt(f\"./data/frame-{i:06d}.pose.txt\")\n",
    "    \n",
    "        # Integrate observation into voxel volume\n",
    "        tsdf_volume.integrate(color_image, depth_image, camera_intrinsics, camera_pose)\n",
    "\n",
    "    fps = image_count / (time.time() - start_time)\n",
    "    print(\"Average FPS: {:.2f}\".format(fps))\n",
    "\n",
    "    # Get mesh from voxel volume and save to disk (can be viewed with Meshlab)\n",
    "    print(\"Saving mesh to mesh.ply...\")\n",
    "    points, faces, normals, colors = tsdf_volume.get_mesh()\n",
    "    mesh = Ply(triangles=faces, points=points, normals=normals, colors=colors)\n",
    "    mesh.write('mesh_output.ply')\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405cbfe-39e6-47a1-acf8-af6778b66662",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f481c-f360-43df-b646-d8034c3a9a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec70ee-17e4-4163-b4b3-4d949232f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "z = np.array([1,2,2,0,1])\n",
    "filters = z > 0\n",
    "z[filters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35e605-259c-4873-a1c7-6c7022ee2954",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05259ff9-008d-4ede-b0dd-48a7e195e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce72ea-caaa-4ae9-9303-df1203ce5ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,3], \n",
    "              [3,4],\n",
    "              [5,6]])\n",
    "x[:,0].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ec125d-c231-4bb5-b174-18995da83a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_coords_h = np.hstack((world_points, np.ones(len(world_points), 1)), np.float32())\n",
    "camera_coords_h = camera_pose @ homo_coords\n",
    "camera_coords_c = camera_coords_h[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b725f3-8781-43c3-b3d2-76a8f2bb66d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "worlds_points = np.array([[1,2,3], [1,2,3]])\n",
    "world_coords_h = np.hstack([worlds_points, np.ones((len(worlds_points), 1), np.float32)])\n",
    "world_coords_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58484a8b-066e-46fc-9aa1-d4c52cf8ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pose = np.random.rand(4,4)\n",
    "camera_coords_h = camera_pose @ world_coords_h.T\n",
    "camera_coords_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a56276-0260-4566-b244-6a9a84a791d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47207fcf-f67d-45b4-ac22-0e29f8234ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b95777-ed5f-422f-bee1-6927d56bd76b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f6739d-80df-451c-b2c0-04b319b68b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a108f-ecc2-435f-8b37-7fd3a89be27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.loadtxt(\"./data/camera-intrinsics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec740c-cb66-4f35-81b0-4742d90b3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f998027b-1348-43d8-90bf-46152c0ac1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd88913-675e-4587-92be-f74a2eae4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bcebd-2405-4899-9a8c-48326bd87f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74579570-fefd-4d7a-a9c6-6699ab2bd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675dd34f-b233-41ae-a4d8-18a6b20c0497",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b269a61-6b03-4b83-a625-3294b1bc0a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e6b77-523b-4a11-be53-8a537d246ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for filename in os.listdir('./data'):\n",
    "    if filename.endswith(\".png\"):\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d13b45-ddc3-4c8b-bcee-a6dd382d80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b27c8-08c8-44e2-be81-8afbb87fef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_color = cv2.imread('frame-000000.color.png',cv2.IMREAD_COLOR)\n",
    "img_color.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e2ff5-9376-4f9d-89e4-e066afe01841",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "609c801c-4d03-47d1-8c5c-e9fccaac9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class Ply(object):\n",
    "    \"\"\"Class to represent a ply in memory, read plys, and write plys.\n",
    "    \"\"\"\n",
    "    def __init__(self, ply_path=None, triangles=None, points=None, normals=None, colors=None):\n",
    "        \"\"\"Initialize the in memory ply representation.\n",
    "\n",
    "        Args:\n",
    "            ply_path (str, optional): Path to .ply file to read (note only\n",
    "                supports text mode, not binary mode). Defaults to None.\n",
    "            triangles (numpy.array [k, 3], optional): each row is a list of point indices used to\n",
    "                render triangles. Defaults to None.\n",
    "            points (numpy.array [n, 3], optional): each row represents a 3D point. Defaults to None.\n",
    "            normals (numpy.array [n, 3], optional): each row represents the normal vector for the\n",
    "                corresponding 3D point.. Defaults to None.\n",
    "            colors (numpy.array [n, 3], optional): each row represents the color of the\n",
    "                corresponding 3D point.. Defaults to None.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # If ply path is None, load in triangles, point, normals, colors.\n",
    "        # else load ply from file. If ply_path is specified AND other inputs\n",
    "        # are specified as well, ignore other inputs.\n",
    "        # If normals are not None make sure that there are equal number of points and normals.\n",
    "        # If colors are not None make sure that there are equal number of colors and normals.\n",
    "\n",
    "        self.triangles = []\n",
    "        self.points = []\n",
    "        self.normals = []\n",
    "        self.colors = []\n",
    "\n",
    "        if ply_path is not None:\n",
    "            assert os.path.exists(ply_path)\n",
    "            self.read(ply_path)\n",
    "        else:\n",
    "            # Set from input args.\n",
    "            if triangles is not None:\n",
    "                self.triangles = triangles\n",
    "\n",
    "            if points is not None:\n",
    "                self.points = points\n",
    "\n",
    "            if normals is not None:\n",
    "                self.normals = normals\n",
    "\n",
    "            if colors is not None:\n",
    "                self.colors = colors\n",
    "\n",
    "        if len(self.normals) != 0:\n",
    "            assert len(self.normals) == len(self.points)\n",
    "\n",
    "        if len(self.colors) != 0:\n",
    "            assert len(self.colors) == len(self.points)\n",
    "\n",
    "\n",
    "    def write(self, ply_path):\n",
    "        \"\"\"Write mesh, point cloud, or oriented point cloud to ply file.\n",
    "\n",
    "        Args:\n",
    "            ply_path (str): Output ply path.\n",
    "        \"\"\"\n",
    "        with open(ply_path, 'w') as f:\n",
    "            # Write header.\n",
    "            f.write('ply\\n')\n",
    "            f.write('format ascii 1.0\\n')\n",
    "            f.write('element vertex {}\\n'.format(len(self.points)))\n",
    "            f.write('property float x\\n')\n",
    "            f.write('property float y\\n')\n",
    "            f.write('property float z\\n')\n",
    "\n",
    "            if len(self.normals) != 0:\n",
    "                f.write('property float nx\\n')\n",
    "                f.write('property float ny\\n')\n",
    "                f.write('property float nz\\n')\n",
    "\n",
    "            if len(self.colors) != 0:\n",
    "                f.write('property uchar red\\n')\n",
    "                f.write('property uchar green\\n')\n",
    "                f.write('property uchar blue\\n')\n",
    "\n",
    "            # Write faces header if dumping triangles.\n",
    "            if len(self.triangles) != 0:\n",
    "                f.write('element face {}\\n'.format(len(self.triangles)))\n",
    "                f.write('property list uchar int vertex_index\\n')\n",
    "\n",
    "            f.write('end_header\\n')\n",
    "\n",
    "            # Write points.\n",
    "            for i in range(len(self.points)):\n",
    "                f.write('{0} {1} {2}'.format(\n",
    "                    self.points[i][0],\n",
    "                    self.points[i][1],\n",
    "                    self.points[i][2]))\n",
    "\n",
    "                if len(self.normals) != 0:\n",
    "                    f.write(' {0} {1} {2}'.format(\n",
    "                        self.normals[i][0],\n",
    "                        self.normals[i][1],\n",
    "                        self.normals[i][2]))\n",
    "\n",
    "                if len(self.colors) != 0:\n",
    "                    f.write(' {0} {1} {2}'.format(\n",
    "                        int(self.colors[i][0]),\n",
    "                        int(self.colors[i][1]),\n",
    "                        int(self.colors[i][2])))\n",
    "\n",
    "                f.write('\\n')\n",
    "\n",
    "            # write triangles if they exist\n",
    "            for triangle in self.triangles:\n",
    "                f.write('3 {0} {1} {2}\\n'.format(triangle[0], triangle[1], triangle[2]))\n",
    "\n",
    "    def read(self, ply_path):\n",
    "        \"\"\"Read a ply into memory.\n",
    "\n",
    "        Args:\n",
    "            ply_path (str): ply to read in.\n",
    "        \"\"\"\n",
    "        vertex_mode = False\n",
    "        face_mode = False\n",
    "        num_points = 0\n",
    "        num_faces = 0\n",
    "        index = 0\n",
    "\n",
    "        self.points = []\n",
    "        self.normals = []\n",
    "        self.colors = []\n",
    "        self.triangles = []\n",
    "\n",
    "        parse_order = []\n",
    "\n",
    "        with open(ply_path, 'r') as ps:\n",
    "            for line in ps:\n",
    "                line = line.split()\n",
    "\n",
    "                if vertex_mode:\n",
    "                    # Read in points and normals.\n",
    "                    property_dict = {}\n",
    "\n",
    "                    assert len(parse_order) == len(line)\n",
    "\n",
    "                    for i, key in enumerate(parse_order):\n",
    "                        property_dict[key] = float(line[i])\n",
    "\n",
    "                    if ('x' in property_dict) and ('y' in property_dict) and ('z' in property_dict):\n",
    "                        self.points.append([property_dict['x'], property_dict['y'], property_dict['z']])\n",
    "                    if ('nx' in property_dict) and ('ny' in property_dict) and ('nz' in property_dict):\n",
    "                        self.normals.append([property_dict['nx'], property_dict['ny'], property_dict['nz']])\n",
    "                    if ('red' in property_dict) and ('green' in property_dict) and ('blue' in property_dict):\n",
    "                        self.colors.append([property_dict['red'], property_dict['green'], property_dict['blue']])\n",
    "                    index += 1\n",
    "                    if index == num_points:\n",
    "                        vertex_mode = False\n",
    "                        face_mode = True\n",
    "                        index = 0\n",
    "                elif face_mode:\n",
    "                    # Read in triangles.\n",
    "                    self.triangles.append([int(i) for i in line[1:4]])\n",
    "                    index += 1\n",
    "                    if index == num_faces:\n",
    "                        face_mode = False\n",
    "                elif line[0] == 'element':\n",
    "                    # set number of lines for vertices and faces.\n",
    "                    if line[1] == 'vertex':\n",
    "                        num_points = int(line[2])\n",
    "                    elif line[1] == 'face':\n",
    "                        num_faces = int(line[2])\n",
    "                elif line[0] == 'property' and num_faces <= 0:\n",
    "                    parse_order.append(line[2])\n",
    "                elif line[0] == 'end_header':\n",
    "                    vertex_mode = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa0099f-a25b-4e1a-8f49-0fa94ca5ec5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
